{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Preparation:\n",
    "\n",
    "First of all we have done a data cleaning of the database to have everything in a proper way to use an algorithm of machine learning.\n",
    "\n",
    "After that, we created the features that are going to be used for the model.\n",
    "We took into account for each team (away and home) the rank they have in the league at the moment of the game, also the points they obtained out of the total possible (relative strenght). For example, being in the tenth matchday a team can be in the sixth position of the championship, but have a difference of 5 points with the fifteenth team, this means that there is an small difference in the mid-table, so, it is really usefull to take into account not only the position in the championship, but the relative strenght too.\n",
    "As well, a team attack and defend different when play at home or away, knowing that the public do a lot cheering for their team and the stadiums differ from each other in the exact measures and the quality of the field (especially in the older games), so, we took into account the amount of goals scored by a team at home and away, and also the amount of goals received at home and away.\n",
    "Also, it is important the form of a team over the year, taking into account that the teams usually play only in weekends and the type of injuries that happen in football, made us to put as a feature the streak of the team in the last five games, because more it is too much and less games is a streak too short.\n",
    "The other features, are basic feautures such as teams, points of each team, score, matchday, division, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>season</th>\n",
       "      <th>division</th>\n",
       "      <th>matchday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2:3</td>\n",
       "      <td>Arenas Club</td>\n",
       "      <td>Athletic Madrid</td>\n",
       "      <td>1928-1929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3:2</td>\n",
       "      <td>Espanyol</td>\n",
       "      <td>Real Unión</td>\n",
       "      <td>1928-1929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5:0</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Catalunya</td>\n",
       "      <td>1928-1929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1:1</td>\n",
       "      <td>Donostia</td>\n",
       "      <td>Athletic</td>\n",
       "      <td>1928-1929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0:2</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>1928-1929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score    home_team        away_team     season  division  matchday\n",
       "0   2:3  Arenas Club  Athletic Madrid  1928-1929         1         1\n",
       "1   3:2     Espanyol       Real Unión  1928-1929         1         1\n",
       "2   5:0  Real Madrid        Catalunya  1928-1929         1         1\n",
       "3   1:1     Donostia         Athletic  1928-1929         1         1\n",
       "4   0:2       Racing        Barcelona  1928-1929         1         1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('../laliga.sqlite')\n",
    "\n",
    "# Query to select the relevant columns from the matches table\n",
    "query = '''\n",
    "SELECT score, home_team, away_team, season, division, matchday\n",
    "FROM Matches\n",
    "'''\n",
    "\n",
    "# Run the query and store the results in a DataFrame\n",
    "matches_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Drop rows with null scores\n",
    "matches_df.dropna(subset=['score'], inplace=True)\n",
    "\n",
    "# Apply the date formatting function to the date column\n",
    "#matches_df['date'] = matches_df['date'].apply(parse_date_mdy_format)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "matches_df.head()  # Display the first few rows of the DataFrame to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to determine match outcomes \n",
    "def determine_outcome(home_goals, away_goals):\n",
    "    if home_goals > away_goals:\n",
    "        return 'W', 'L'\n",
    "    elif home_goals < away_goals:\n",
    "        return 'L', 'W'\n",
    "    else:\n",
    "        return 'T', 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_single_season_division_standings(season, division, matches_df):\n",
    "    # Filter matches for the given season and division\n",
    "    season_matches = matches_df[(matches_df['season'] == season) & (matches_df['division'] == division)].sort_values('matchday')\n",
    "    matchdays = season_matches['matchday'].unique()\n",
    "\n",
    "    # Initialize the standings dict with teams\n",
    "    teams = pd.unique(season_matches[['home_team', 'away_team']].values.ravel('K'))\n",
    "    standings_tracker = {team: {'GF_home': 0, 'GA_home': 0, 'GF_away': 0, 'GA_away': 0, 'W': 0, 'L': 0, 'T': 0, 'PTS': 0, 'last_5': []} for team in teams}\n",
    "\n",
    "    # Function to determine match outcome\n",
    "    def determine_outcome(home_goals, away_goals):\n",
    "        if home_goals > away_goals:\n",
    "            return 'W', 'L'\n",
    "        elif home_goals < away_goals:\n",
    "            return 'L', 'W'\n",
    "        return 'T', 'T'\n",
    "\n",
    "    # Function to calculate relative strength\n",
    "    def calculate_relative_strength(standings_df, matchday):\n",
    "        # Calculate the maximum possible points so far for each team\n",
    "        max_points_so_far = matchday * 3\n",
    "        # Calculate the relative strength for each team as the percentage of points obtained out of the total possible\n",
    "        standings_df['relative_strength'] = standings_df['PTS'] / max_points_so_far * 100\n",
    "        return standings_df\n",
    "\n",
    "    # List to collect matchday standings\n",
    "    all_standings = []\n",
    "\n",
    "    # Process each matchday\n",
    "    for matchday in matchdays:\n",
    "        matchday_matches = season_matches[season_matches['matchday'] == matchday]\n",
    "        for index, match in matchday_matches.iterrows():\n",
    "            home_team, away_team = match['home_team'], match['away_team']\n",
    "            home_goals, away_goals = map(int, match['score'].split(':'))\n",
    "            home_outcome, away_outcome = determine_outcome(home_goals, away_goals)\n",
    "\n",
    "            # Update goals for and against at home and away\n",
    "            standings_tracker[home_team]['GF_home'] += home_goals\n",
    "            standings_tracker[away_team]['GF_away'] += away_goals\n",
    "            standings_tracker[home_team]['GA_home'] += away_goals\n",
    "            standings_tracker[away_team]['GA_away'] += home_goals\n",
    "\n",
    "            # Update last 5 matches\n",
    "            if matchday > 1:  # Only update if it's not the first matchday\n",
    "                standings_tracker[home_team]['last_5'].insert(0, home_outcome)\n",
    "                standings_tracker[away_team]['last_5'].insert(0, away_outcome)\n",
    "\n",
    "            # Ensure last_5 lists do not exceed 5 matches\n",
    "            standings_tracker[home_team]['last_5'] = standings_tracker[home_team]['last_5'][:5]\n",
    "            standings_tracker[away_team]['last_5'] = standings_tracker[away_team]['last_5'][:5]\n",
    "\n",
    "            # Update wins, losses, ties, and points\n",
    "            if home_goals > away_goals:  # Home win\n",
    "                standings_tracker[home_team]['W'] += 1\n",
    "                standings_tracker[home_team]['PTS'] += 3\n",
    "                standings_tracker[away_team]['L'] += 1\n",
    "            elif home_goals < away_goals:  # Away win\n",
    "                standings_tracker[away_team]['W'] += 1\n",
    "                standings_tracker[away_team]['PTS'] += 3\n",
    "                standings_tracker[home_team]['L'] += 1\n",
    "            else:  # Tie\n",
    "                standings_tracker[home_team]['T'] += 1\n",
    "                standings_tracker[home_team]['PTS'] += 1\n",
    "                standings_tracker[away_team]['T'] += 1\n",
    "                standings_tracker[away_team]['PTS'] += 1\n",
    "\n",
    "        # Calculate goal difference for each team\n",
    "        for team in teams:\n",
    "            standings_tracker[team]['GD'] = standings_tracker[team]['GF_home'] + standings_tracker[team]['GF_away'] - \\\n",
    "                                             standings_tracker[team]['GA_home'] - standings_tracker[team]['GA_away']\n",
    "\n",
    "        # Create standings DataFrame for the current matchday\n",
    "        matchday_standings = (pd.DataFrame.from_dict(standings_tracker, orient='index')\n",
    "                                .reset_index()\n",
    "                                .rename(columns={'index': 'team'}))\n",
    "        matchday_standings['matchday'] = matchday\n",
    "        matchday_standings['season'] = season\n",
    "        matchday_standings['division'] = division\n",
    "\n",
    "        # Sort standings\n",
    "        matchday_standings.sort_values(by=['PTS', 'GD', 'GF_home', 'GF_away'], ascending=[False, False, False, False], inplace=True)\n",
    "        matchday_standings['rank'] = matchday_standings.reset_index(drop=True).index + 1\n",
    "\n",
    "        # Calculate the relative strength\n",
    "        matchday_standings = calculate_relative_strength(matchday_standings, matchday)\n",
    "\n",
    "        # Append to the list\n",
    "        all_standings.append(matchday_standings)\n",
    "\n",
    "    # Concatenate all matchday standings\n",
    "    final_standings = pd.concat(all_standings, ignore_index=True)\n",
    "    # Reorder columns\n",
    "    final_standings = final_standings[['season', 'division', 'matchday', 'rank', 'team', 'GD', 'GF_home', 'GA_home', 'GF_away', 'GA_away', 'W', 'L', 'T', 'PTS', 'last_5', 'relative_strength']]\n",
    "    \n",
    "    return final_standings\n",
    "\n",
    "# Use this function to generate the standings for a given season and division\n",
    "#calculate_single_season_division_standings('2020-2021', 1, matches_df)\n",
    "\n",
    "def calculate_all_seasons_divisions_standings(matches_df):\n",
    "    # Initialize the final DataFrame\n",
    "    final_all_standings = pd.DataFrame()\n",
    "\n",
    "    # Process each season and division without explicit loops\n",
    "    for (season, division), group_df in matches_df.groupby(['season', 'division']):\n",
    "        season_division_standings = calculate_single_season_division_standings(season, division, group_df)\n",
    "        final_all_standings = pd.concat([final_all_standings, season_division_standings], ignore_index=True)\n",
    "\n",
    "    return final_all_standings\n",
    "\n",
    "features_df = calculate_all_seasons_divisions_standings(matches_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_match_outcome(score):\n",
    "    home_goals, away_goals = map(int, score.split(':'))\n",
    "    if home_goals > away_goals:\n",
    "        return '1'  # Home win\n",
    "    elif home_goals < away_goals:\n",
    "        return '2'  # Away win\n",
    "    else:\n",
    "        return 'X'  # Draw\n",
    "\n",
    "# Apply the encoding function to the score column\n",
    "matches_df['outcome'] = matches_df['score'].apply(encode_match_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'home_team', 'away_team', 'season', 'division', 'matchday', 'outcome']\n",
      "['season', 'division', 'matchday', 'rank', 'team', 'GD', 'GF_home', 'GA_home', 'GF_away', 'GA_away', 'PTS', 'last_5', 'relative_strength']\n"
     ]
    }
   ],
   "source": [
    "print(matches_df.columns.to_list())\n",
    "\n",
    "features_df.drop(['W', 'L', 'T'], axis=1, inplace=True)\n",
    "print(features_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'home_team', 'away_team', 'season', 'division', 'matchday', 'outcome', 'rank', 'team', 'GD', 'GF_home', 'GA_home', 'GF_away', 'GA_away', 'PTS', 'last_5', 'relative_strength', 'rank_AwayTeam', 'team_away', 'GD_AwayTeam', 'GFH_AwayTeam', 'GAH_AwayTeam', 'GFA_AwayTeam', 'GAA_AwayTeam', 'PTS_AwayTeam', 'last_5_AwayTeam', 'relative_strength_AwayTeam']\n"
     ]
    }
   ],
   "source": [
    "# First merge for Home Team features\n",
    "matches_df = pd.merge(\n",
    "    left=matches_df,\n",
    "    right=features_df,\n",
    "    how='left',\n",
    "    left_on=['season', 'division', 'matchday', 'home_team'],\n",
    "    right_on=['season', 'division', 'matchday', 'team'],\n",
    "    suffixes=('', '_home')\n",
    ")\n",
    "\n",
    "# Rename the merged columns for the Home Team\n",
    "home_feature_columns = {\n",
    "    'GD_home' : 'GD_HomeTeam',\n",
    "    'GF_home_home': 'GFH_HomeTeam',\n",
    "    'GA_home_home': 'GAH_HomeTeam',\n",
    "    'GF_away_home': 'GFA_HomeTeam',\n",
    "    'GA_away_home': 'GAA_HomeTeam',\n",
    "    'PTS_home': 'PTS_HomeTeam',\n",
    "    'last_5_home': 'last_5_HomeTeam',\n",
    "    'relative_strength_home': 'relative_strength_HomeTeam',\n",
    "    'rank_home': 'rank_HomeTeam'\n",
    "}\n",
    "matches_df.rename(columns=home_feature_columns, inplace=True)\n",
    "\n",
    "# Second merge for Away Team features\n",
    "matches_df = pd.merge(\n",
    "    left=matches_df,\n",
    "    right=features_df,\n",
    "    how='left',\n",
    "    left_on=['season', 'division', 'matchday', 'away_team'],\n",
    "    right_on=['season', 'division', 'matchday', 'team'],\n",
    "    suffixes=('', '_away')\n",
    ")\n",
    "\n",
    "# Rename the merged columns for the Away Team\n",
    "away_feature_columns = {\n",
    "    'GD_away' : 'GD_AwayTeam',\n",
    "    'GF_home_away': 'GFH_AwayTeam',\n",
    "    'GA_home_away': 'GAH_AwayTeam',\n",
    "    'GF_away_away': 'GFA_AwayTeam',\n",
    "    'GA_away_away': 'GAA_AwayTeam',\n",
    "    'PTS_away': 'PTS_AwayTeam',\n",
    "    'last_5_away': 'last_5_AwayTeam',\n",
    "    'relative_strength_away': 'relative_strength_AwayTeam',\n",
    "    'rank_away': 'rank_AwayTeam'\n",
    "}\n",
    "matches_df.rename(columns=away_feature_columns, inplace=True)\n",
    "\n",
    "\n",
    "print(matches_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'season', 'division', 'matchday', 'outcome', 'rank', 'team', 'GD', 'GF_home', 'GA_home', 'GF_away', 'GA_away', 'PTS', 'last_5', 'relative_strength', 'rank_AwayTeam', 'GD_AwayTeam', 'GFH_AwayTeam', 'GAH_AwayTeam', 'GFA_AwayTeam', 'GAA_AwayTeam', 'PTS_AwayTeam', 'last_5_AwayTeam', 'relative_strength_AwayTeam', 'season_start', 'season_since_start']\n"
     ]
    }
   ],
   "source": [
    "matches_df.drop(['home_team', 'away_team', 'team_away'], axis=1, inplace=True)\n",
    "\n",
    "matches_df['season_start'] = matches_df['season'].apply(lambda x: int(x.split('-')[0]))\n",
    "min_season = matches_df['season_start'].min()\n",
    "matches_df['season_since_start'] = matches_df['season_start'] - min_season\n",
    "\n",
    "print(matches_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_last_5(results_list):\n",
    "    # Define points for win, draw, loss\n",
    "    points = {'W': 3, 'D': 1, 'L': 0}\n",
    "    \n",
    "    # Calculate the total points for the last 5 matches\n",
    "    total_points = sum(points[result] for result in results_list if result in points)\n",
    "    \n",
    "    return total_points\n",
    "\n",
    "# Now apply this function to the last_5 column of your DataFrame\n",
    "matches_df['last_5_AwayTeam'] = matches_df['last_5_AwayTeam'].apply(encode_last_5)\n",
    "matches_df['last_5_HomeTeam'] = matches_df['last_5'].apply(encode_last_5)\n",
    "\n",
    "matches_df.drop('last_5', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ML Algorithms:\n",
    "\n",
    "After dealing with the data to prepare it, we tried different algorithms of machine learning with target of the outcome of the match (who wins or if they tie) and a test size of the 20%, because of the characteristics of the problem the algorithms we tried are a random forest, a gradient boosting, a neural network, a recurrent neural network (RNN) and a long short-term memory (LSTM), that is a type of recurrent neural network.\n",
    "\n",
    "After trying all of this algorithms we found that all of them work good with our problem because they have almost 70% of accuracy determining the outcome of the matches. But the one who fits better with our problem is the RNN having 70% of accuracy.\n",
    "This is a good value taking into account that soccer is a very unpredictable sport, so, not having more accuracy is due to that fact. So, we can conclude that this model works good and the features used fit in the model good too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6828125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Encoding categorical features and scaling\n",
    "label_encoder = LabelEncoder()\n",
    "matches_df['season'] = label_encoder.fit_transform(matches_df['season'])\n",
    "\n",
    "# Assuming 'score' is not a feature, and 'PTS' and 'PTS_AwayTeam' are the same, dropping duplicates\n",
    "matches_df.drop(['score', 'team', 'PTS'], axis=1, inplace=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = matches_df.drop('outcome', axis=1)\n",
    "y = matches_df['outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6986458333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the model\n",
    "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "gbm_predictions = gbm.predict(X_test)\n",
    "\n",
    "# You can also evaluate the model performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, gbm_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1200/1200 [==============================] - 1s 775us/step - loss: 2.8435 - accuracy: 0.5314\n",
      "Epoch 2/50\n",
      "1200/1200 [==============================] - 1s 785us/step - loss: 1.3755 - accuracy: 0.5809\n",
      "Epoch 3/50\n",
      "1200/1200 [==============================] - 1s 780us/step - loss: 1.2708 - accuracy: 0.5958\n",
      "Epoch 4/50\n",
      "1200/1200 [==============================] - 1s 784us/step - loss: 1.1568 - accuracy: 0.6071\n",
      "Epoch 5/50\n",
      "1200/1200 [==============================] - 1s 778us/step - loss: 1.1241 - accuracy: 0.6090\n",
      "Epoch 6/50\n",
      "1200/1200 [==============================] - 1s 776us/step - loss: 1.1022 - accuracy: 0.6084\n",
      "Epoch 7/50\n",
      "1200/1200 [==============================] - 1s 760us/step - loss: 1.0550 - accuracy: 0.6124\n",
      "Epoch 8/50\n",
      "1200/1200 [==============================] - 1s 782us/step - loss: 0.9824 - accuracy: 0.6203\n",
      "Epoch 9/50\n",
      "1200/1200 [==============================] - 1s 791us/step - loss: 0.9505 - accuracy: 0.6278\n",
      "Epoch 10/50\n",
      "1200/1200 [==============================] - 1s 782us/step - loss: 0.8997 - accuracy: 0.6341\n",
      "Epoch 11/50\n",
      "1200/1200 [==============================] - 1s 748us/step - loss: 0.8838 - accuracy: 0.6309\n",
      "Epoch 12/50\n",
      "1200/1200 [==============================] - 1s 736us/step - loss: 0.8523 - accuracy: 0.6391\n",
      "Epoch 13/50\n",
      "1200/1200 [==============================] - 1s 744us/step - loss: 0.8503 - accuracy: 0.6387\n",
      "Epoch 14/50\n",
      "1200/1200 [==============================] - 1s 724us/step - loss: 0.8179 - accuracy: 0.6463\n",
      "Epoch 15/50\n",
      "1200/1200 [==============================] - 1s 729us/step - loss: 0.8033 - accuracy: 0.6479\n",
      "Epoch 16/50\n",
      "1200/1200 [==============================] - 1s 736us/step - loss: 0.7834 - accuracy: 0.6554\n",
      "Epoch 17/50\n",
      "1200/1200 [==============================] - 1s 724us/step - loss: 0.7635 - accuracy: 0.6614\n",
      "Epoch 18/50\n",
      "1200/1200 [==============================] - 1s 726us/step - loss: 0.7574 - accuracy: 0.6617\n",
      "Epoch 19/50\n",
      "1200/1200 [==============================] - 1s 741us/step - loss: 0.7486 - accuracy: 0.6651\n",
      "Epoch 20/50\n",
      "1200/1200 [==============================] - 1s 740us/step - loss: 0.7395 - accuracy: 0.6696\n",
      "Epoch 21/50\n",
      "1200/1200 [==============================] - 1s 729us/step - loss: 0.7295 - accuracy: 0.6736\n",
      "Epoch 22/50\n",
      "1200/1200 [==============================] - 1s 726us/step - loss: 0.7274 - accuracy: 0.6736\n",
      "Epoch 23/50\n",
      "1200/1200 [==============================] - 1s 738us/step - loss: 0.7202 - accuracy: 0.6789\n",
      "Epoch 24/50\n",
      "1200/1200 [==============================] - 1s 727us/step - loss: 0.7225 - accuracy: 0.6757\n",
      "Epoch 25/50\n",
      "1200/1200 [==============================] - 1s 726us/step - loss: 0.7082 - accuracy: 0.6816\n",
      "Epoch 26/50\n",
      "1200/1200 [==============================] - 1s 740us/step - loss: 0.7105 - accuracy: 0.6825\n",
      "Epoch 27/50\n",
      "1200/1200 [==============================] - 1s 728us/step - loss: 0.7088 - accuracy: 0.6823\n",
      "Epoch 28/50\n",
      "1200/1200 [==============================] - 1s 727us/step - loss: 0.7103 - accuracy: 0.6812\n",
      "Epoch 29/50\n",
      "1200/1200 [==============================] - 1s 729us/step - loss: 0.7033 - accuracy: 0.6870\n",
      "Epoch 30/50\n",
      "1200/1200 [==============================] - 1s 736us/step - loss: 0.7035 - accuracy: 0.6848\n",
      "Epoch 31/50\n",
      "1200/1200 [==============================] - 1s 725us/step - loss: 0.7020 - accuracy: 0.6857\n",
      "Epoch 32/50\n",
      "1200/1200 [==============================] - 1s 728us/step - loss: 0.6956 - accuracy: 0.6877\n",
      "Epoch 33/50\n",
      "1200/1200 [==============================] - 1s 728us/step - loss: 0.6936 - accuracy: 0.6886\n",
      "Epoch 34/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.6968 - accuracy: 0.6868\n",
      "Epoch 35/50\n",
      "1200/1200 [==============================] - 1s 731us/step - loss: 0.6952 - accuracy: 0.6902\n",
      "Epoch 36/50\n",
      "1200/1200 [==============================] - 1s 739us/step - loss: 0.6932 - accuracy: 0.6896\n",
      "Epoch 37/50\n",
      "1200/1200 [==============================] - 1s 762us/step - loss: 0.6933 - accuracy: 0.6886\n",
      "Epoch 38/50\n",
      "1200/1200 [==============================] - 1s 732us/step - loss: 0.6947 - accuracy: 0.6883\n",
      "Epoch 39/50\n",
      "1200/1200 [==============================] - 1s 729us/step - loss: 0.6917 - accuracy: 0.6884\n",
      "Epoch 40/50\n",
      "1200/1200 [==============================] - 1s 730us/step - loss: 0.6898 - accuracy: 0.6919\n",
      "Epoch 41/50\n",
      "1200/1200 [==============================] - 1s 734us/step - loss: 0.6889 - accuracy: 0.6889\n",
      "Epoch 42/50\n",
      "1200/1200 [==============================] - 1s 737us/step - loss: 0.6880 - accuracy: 0.6902\n",
      "Epoch 43/50\n",
      "1200/1200 [==============================] - 1s 742us/step - loss: 0.6862 - accuracy: 0.6907\n",
      "Epoch 44/50\n",
      "1200/1200 [==============================] - 1s 731us/step - loss: 0.6867 - accuracy: 0.6901\n",
      "Epoch 45/50\n",
      "1200/1200 [==============================] - 1s 730us/step - loss: 0.6880 - accuracy: 0.6898\n",
      "Epoch 46/50\n",
      "1200/1200 [==============================] - 1s 747us/step - loss: 0.6835 - accuracy: 0.6900\n",
      "Epoch 47/50\n",
      "1200/1200 [==============================] - 1s 736us/step - loss: 0.6870 - accuracy: 0.6895\n",
      "Epoch 48/50\n",
      "1200/1200 [==============================] - 1s 741us/step - loss: 0.6855 - accuracy: 0.6915\n",
      "Epoch 49/50\n",
      "1200/1200 [==============================] - 1s 747us/step - loss: 0.6856 - accuracy: 0.6913\n",
      "Epoch 50/50\n",
      "1200/1200 [==============================] - 1s 735us/step - loss: 0.6852 - accuracy: 0.6920\n",
      "300/300 [==============================] - 0s 692us/step - loss: 0.6748 - accuracy: 0.6936\n",
      "Test accuracy: 0.6936458349227905\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have your input features in `X` and labels in `y` as a pandas Series or numpy array\n",
    "\n",
    "# Step 1: Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_integers = label_encoder.fit_transform(y)\n",
    "y_encoded = to_categorical(y_integers, num_classes=3)\n",
    "\n",
    "# Step 2: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Create the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes for win, draw, loss\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1200/1200 - 2s - loss: 0.8066 - accuracy: 0.6396 - val_loss: 0.7414 - val_accuracy: 0.6819 - 2s/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "1200/1200 - 1s - loss: 0.7381 - accuracy: 0.6786 - val_loss: 0.7213 - val_accuracy: 0.6865 - 1s/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "1200/1200 - 1s - loss: 0.7253 - accuracy: 0.6817 - val_loss: 0.7137 - val_accuracy: 0.6828 - 1s/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "1200/1200 - 1s - loss: 0.7221 - accuracy: 0.6813 - val_loss: 0.7151 - val_accuracy: 0.6803 - 1s/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "1200/1200 - 1s - loss: 0.7176 - accuracy: 0.6812 - val_loss: 0.7061 - val_accuracy: 0.6843 - 1s/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "1200/1200 - 1s - loss: 0.7144 - accuracy: 0.6831 - val_loss: 0.7006 - val_accuracy: 0.6911 - 1s/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "1200/1200 - 1s - loss: 0.7114 - accuracy: 0.6852 - val_loss: 0.6983 - val_accuracy: 0.6873 - 1s/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "1200/1200 - 1s - loss: 0.7081 - accuracy: 0.6842 - val_loss: 0.7019 - val_accuracy: 0.6904 - 1s/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "1200/1200 - 1s - loss: 0.7036 - accuracy: 0.6868 - val_loss: 0.6936 - val_accuracy: 0.6886 - 1s/epoch - 981us/step\n",
      "Epoch 10/50\n",
      "1200/1200 - 1s - loss: 0.7010 - accuracy: 0.6887 - val_loss: 0.6931 - val_accuracy: 0.6950 - 1s/epoch - 979us/step\n",
      "Epoch 11/50\n",
      "1200/1200 - 1s - loss: 0.6979 - accuracy: 0.6893 - val_loss: 0.6886 - val_accuracy: 0.6966 - 1s/epoch - 983us/step\n",
      "Epoch 12/50\n",
      "1200/1200 - 1s - loss: 0.6953 - accuracy: 0.6894 - val_loss: 0.6889 - val_accuracy: 0.6886 - 1s/epoch - 984us/step\n",
      "Epoch 13/50\n",
      "1200/1200 - 1s - loss: 0.6919 - accuracy: 0.6903 - val_loss: 0.6838 - val_accuracy: 0.6970 - 1s/epoch - 984us/step\n",
      "Epoch 14/50\n",
      "1200/1200 - 1s - loss: 0.6905 - accuracy: 0.6924 - val_loss: 0.6860 - val_accuracy: 0.6971 - 1s/epoch - 982us/step\n",
      "Epoch 15/50\n",
      "1200/1200 - 1s - loss: 0.6882 - accuracy: 0.6918 - val_loss: 0.6839 - val_accuracy: 0.6927 - 1s/epoch - 994us/step\n",
      "Epoch 16/50\n",
      "1200/1200 - 1s - loss: 0.6869 - accuracy: 0.6925 - val_loss: 0.6833 - val_accuracy: 0.6916 - 1s/epoch - 980us/step\n",
      "Epoch 17/50\n",
      "1200/1200 - 1s - loss: 0.6854 - accuracy: 0.6925 - val_loss: 0.6852 - val_accuracy: 0.6921 - 1s/epoch - 986us/step\n",
      "Epoch 18/50\n",
      "1200/1200 - 1s - loss: 0.6833 - accuracy: 0.6929 - val_loss: 0.6771 - val_accuracy: 0.6954 - 1s/epoch - 981us/step\n",
      "Epoch 19/50\n",
      "1200/1200 - 1s - loss: 0.6823 - accuracy: 0.6921 - val_loss: 0.6801 - val_accuracy: 0.6923 - 1s/epoch - 987us/step\n",
      "Epoch 20/50\n",
      "1200/1200 - 1s - loss: 0.6807 - accuracy: 0.6941 - val_loss: 0.6759 - val_accuracy: 0.6966 - 1s/epoch - 980us/step\n",
      "Epoch 21/50\n",
      "1200/1200 - 1s - loss: 0.6804 - accuracy: 0.6923 - val_loss: 0.6751 - val_accuracy: 0.6951 - 1s/epoch - 976us/step\n",
      "Epoch 22/50\n",
      "1200/1200 - 1s - loss: 0.6793 - accuracy: 0.6928 - val_loss: 0.6730 - val_accuracy: 0.6981 - 1s/epoch - 978us/step\n",
      "Epoch 23/50\n",
      "1200/1200 - 1s - loss: 0.6787 - accuracy: 0.6921 - val_loss: 0.6708 - val_accuracy: 0.6982 - 1s/epoch - 969us/step\n",
      "Epoch 24/50\n",
      "1200/1200 - 1s - loss: 0.6774 - accuracy: 0.6941 - val_loss: 0.6712 - val_accuracy: 0.6989 - 1s/epoch - 966us/step\n",
      "Epoch 25/50\n",
      "1200/1200 - 1s - loss: 0.6773 - accuracy: 0.6945 - val_loss: 0.6711 - val_accuracy: 0.6984 - 1s/epoch - 978us/step\n",
      "Epoch 26/50\n",
      "1200/1200 - 1s - loss: 0.6754 - accuracy: 0.6951 - val_loss: 0.6718 - val_accuracy: 0.6969 - 1s/epoch - 986us/step\n",
      "Epoch 27/50\n",
      "1200/1200 - 1s - loss: 0.6756 - accuracy: 0.6943 - val_loss: 0.6738 - val_accuracy: 0.6933 - 1s/epoch - 982us/step\n",
      "Epoch 28/50\n",
      "1200/1200 - 1s - loss: 0.6746 - accuracy: 0.6949 - val_loss: 0.6702 - val_accuracy: 0.6981 - 1s/epoch - 966us/step\n",
      "Epoch 29/50\n",
      "1200/1200 - 1s - loss: 0.6746 - accuracy: 0.6954 - val_loss: 0.6694 - val_accuracy: 0.6984 - 1s/epoch - 967us/step\n",
      "Epoch 30/50\n",
      "1200/1200 - 1s - loss: 0.6742 - accuracy: 0.6937 - val_loss: 0.6790 - val_accuracy: 0.6903 - 1s/epoch - 978us/step\n",
      "Epoch 31/50\n",
      "1200/1200 - 1s - loss: 0.6737 - accuracy: 0.6933 - val_loss: 0.6687 - val_accuracy: 0.6979 - 1s/epoch - 984us/step\n",
      "Epoch 32/50\n",
      "1200/1200 - 1s - loss: 0.6729 - accuracy: 0.6969 - val_loss: 0.6718 - val_accuracy: 0.6967 - 1s/epoch - 982us/step\n",
      "Epoch 33/50\n",
      "1200/1200 - 1s - loss: 0.6728 - accuracy: 0.6943 - val_loss: 0.6724 - val_accuracy: 0.6966 - 1s/epoch - 986us/step\n",
      "Epoch 34/50\n",
      "1200/1200 - 1s - loss: 0.6720 - accuracy: 0.6967 - val_loss: 0.6697 - val_accuracy: 0.6974 - 1s/epoch - 984us/step\n",
      "Epoch 35/50\n",
      "1200/1200 - 1s - loss: 0.6720 - accuracy: 0.6952 - val_loss: 0.6707 - val_accuracy: 0.6976 - 1s/epoch - 994us/step\n",
      "Epoch 36/50\n",
      "1200/1200 - 1s - loss: 0.6715 - accuracy: 0.6935 - val_loss: 0.6687 - val_accuracy: 0.6991 - 1s/epoch - 982us/step\n",
      "Epoch 37/50\n",
      "1200/1200 - 1s - loss: 0.6708 - accuracy: 0.6959 - val_loss: 0.6689 - val_accuracy: 0.6986 - 1s/epoch - 971us/step\n",
      "Epoch 38/50\n",
      "1200/1200 - 1s - loss: 0.6708 - accuracy: 0.6972 - val_loss: 0.6732 - val_accuracy: 0.6984 - 1s/epoch - 993us/step\n",
      "Epoch 39/50\n",
      "1200/1200 - 1s - loss: 0.6700 - accuracy: 0.6962 - val_loss: 0.6685 - val_accuracy: 0.6975 - 1s/epoch - 990us/step\n",
      "Epoch 40/50\n",
      "1200/1200 - 1s - loss: 0.6701 - accuracy: 0.6962 - val_loss: 0.6686 - val_accuracy: 0.7011 - 1s/epoch - 992us/step\n",
      "Epoch 41/50\n",
      "1200/1200 - 1s - loss: 0.6697 - accuracy: 0.6975 - val_loss: 0.6675 - val_accuracy: 0.6981 - 1s/epoch - 969us/step\n",
      "Epoch 42/50\n",
      "1200/1200 - 1s - loss: 0.6691 - accuracy: 0.6963 - val_loss: 0.6688 - val_accuracy: 0.6982 - 1s/epoch - 957us/step\n",
      "Epoch 43/50\n",
      "1200/1200 - 1s - loss: 0.6688 - accuracy: 0.6966 - val_loss: 0.6668 - val_accuracy: 0.6984 - 1s/epoch - 976us/step\n",
      "Epoch 44/50\n",
      "1200/1200 - 1s - loss: 0.6682 - accuracy: 0.6971 - val_loss: 0.6703 - val_accuracy: 0.6974 - 1s/epoch - 987us/step\n",
      "Epoch 45/50\n",
      "1200/1200 - 1s - loss: 0.6682 - accuracy: 0.6968 - val_loss: 0.6672 - val_accuracy: 0.6989 - 1s/epoch - 989us/step\n",
      "Epoch 46/50\n",
      "1200/1200 - 1s - loss: 0.6678 - accuracy: 0.6967 - val_loss: 0.6685 - val_accuracy: 0.6980 - 1s/epoch - 973us/step\n",
      "Epoch 47/50\n",
      "1200/1200 - 1s - loss: 0.6677 - accuracy: 0.6971 - val_loss: 0.6668 - val_accuracy: 0.6999 - 1s/epoch - 982us/step\n",
      "Epoch 48/50\n",
      "1200/1200 - 1s - loss: 0.6672 - accuracy: 0.6982 - val_loss: 0.6661 - val_accuracy: 0.6981 - 1s/epoch - 996us/step\n",
      "Epoch 49/50\n",
      "1200/1200 - 1s - loss: 0.6668 - accuracy: 0.6963 - val_loss: 0.6694 - val_accuracy: 0.6984 - 1s/epoch - 971us/step\n",
      "Epoch 50/50\n",
      "1200/1200 - 1s - loss: 0.6673 - accuracy: 0.6973 - val_loss: 0.6716 - val_accuracy: 0.6983 - 1s/epoch - 965us/step\n",
      "Test Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_integers = label_encoder.fit_transform(y)\n",
    "y_encoded = to_categorical(y_integers, num_classes=3)\n",
    "\n",
    "# Step 2: Normalize the features (assuming X is a DataFrame for this example)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape input data to be 3D [samples, timesteps, features] for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Step 4: Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(3, activation='softmax')) # Output layer with 3 units for each class\n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Fit the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1200/1200 - 2s - loss: 0.7884 - accuracy: 0.6506 - val_loss: 0.7290 - val_accuracy: 0.6831 - 2s/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "1200/1200 - 1s - loss: 0.7293 - accuracy: 0.6771 - val_loss: 0.7117 - val_accuracy: 0.6854 - 1s/epoch - 942us/step\n",
      "Epoch 3/50\n",
      "1200/1200 - 1s - loss: 0.7185 - accuracy: 0.6812 - val_loss: 0.7054 - val_accuracy: 0.6881 - 1s/epoch - 969us/step\n",
      "Epoch 4/50\n",
      "1200/1200 - 1s - loss: 0.7127 - accuracy: 0.6837 - val_loss: 0.7006 - val_accuracy: 0.6905 - 1s/epoch - 954us/step\n",
      "Epoch 5/50\n",
      "1200/1200 - 1s - loss: 0.7093 - accuracy: 0.6838 - val_loss: 0.7059 - val_accuracy: 0.6843 - 1s/epoch - 962us/step\n",
      "Epoch 6/50\n",
      "1200/1200 - 1s - loss: 0.7052 - accuracy: 0.6857 - val_loss: 0.6963 - val_accuracy: 0.6864 - 1s/epoch - 955us/step\n",
      "Epoch 7/50\n",
      "1200/1200 - 1s - loss: 0.7024 - accuracy: 0.6873 - val_loss: 0.6940 - val_accuracy: 0.6907 - 1s/epoch - 981us/step\n",
      "Epoch 8/50\n",
      "1200/1200 - 1s - loss: 0.6992 - accuracy: 0.6890 - val_loss: 0.6884 - val_accuracy: 0.6923 - 1s/epoch - 958us/step\n",
      "Epoch 9/50\n",
      "1200/1200 - 1s - loss: 0.6975 - accuracy: 0.6871 - val_loss: 0.6866 - val_accuracy: 0.6923 - 1s/epoch - 947us/step\n",
      "Epoch 10/50\n",
      "1200/1200 - 1s - loss: 0.6950 - accuracy: 0.6894 - val_loss: 0.6912 - val_accuracy: 0.6935 - 1s/epoch - 930us/step\n",
      "Epoch 11/50\n",
      "1200/1200 - 1s - loss: 0.6934 - accuracy: 0.6895 - val_loss: 0.6848 - val_accuracy: 0.6961 - 1s/epoch - 939us/step\n",
      "Epoch 12/50\n",
      "1200/1200 - 1s - loss: 0.6914 - accuracy: 0.6917 - val_loss: 0.6818 - val_accuracy: 0.6953 - 1s/epoch - 928us/step\n",
      "Epoch 13/50\n",
      "1200/1200 - 1s - loss: 0.6886 - accuracy: 0.6920 - val_loss: 0.6811 - val_accuracy: 0.6963 - 1s/epoch - 942us/step\n",
      "Epoch 14/50\n",
      "1200/1200 - 1s - loss: 0.6868 - accuracy: 0.6924 - val_loss: 0.6772 - val_accuracy: 0.6967 - 1s/epoch - 938us/step\n",
      "Epoch 15/50\n",
      "1200/1200 - 1s - loss: 0.6843 - accuracy: 0.6939 - val_loss: 0.6768 - val_accuracy: 0.6969 - 1s/epoch - 941us/step\n",
      "Epoch 16/50\n",
      "1200/1200 - 1s - loss: 0.6831 - accuracy: 0.6940 - val_loss: 0.6790 - val_accuracy: 0.7002 - 1s/epoch - 940us/step\n",
      "Epoch 17/50\n",
      "1200/1200 - 1s - loss: 0.6814 - accuracy: 0.6934 - val_loss: 0.6765 - val_accuracy: 0.6953 - 1s/epoch - 937us/step\n",
      "Epoch 18/50\n",
      "1200/1200 - 1s - loss: 0.6807 - accuracy: 0.6941 - val_loss: 0.6722 - val_accuracy: 0.6984 - 1s/epoch - 935us/step\n",
      "Epoch 19/50\n",
      "1200/1200 - 1s - loss: 0.6795 - accuracy: 0.6946 - val_loss: 0.6756 - val_accuracy: 0.6952 - 1s/epoch - 943us/step\n",
      "Epoch 20/50\n",
      "1200/1200 - 1s - loss: 0.6787 - accuracy: 0.6941 - val_loss: 0.6765 - val_accuracy: 0.6970 - 1s/epoch - 961us/step\n",
      "Epoch 21/50\n",
      "1200/1200 - 1s - loss: 0.6781 - accuracy: 0.6947 - val_loss: 0.6702 - val_accuracy: 0.7000 - 1s/epoch - 935us/step\n",
      "Epoch 22/50\n",
      "1200/1200 - 1s - loss: 0.6773 - accuracy: 0.6945 - val_loss: 0.6697 - val_accuracy: 0.6967 - 1s/epoch - 948us/step\n",
      "Epoch 23/50\n",
      "1200/1200 - 1s - loss: 0.6761 - accuracy: 0.6945 - val_loss: 0.6724 - val_accuracy: 0.6961 - 1s/epoch - 958us/step\n",
      "Epoch 24/50\n",
      "1200/1200 - 1s - loss: 0.6752 - accuracy: 0.6958 - val_loss: 0.6669 - val_accuracy: 0.7000 - 1s/epoch - 945us/step\n",
      "Epoch 25/50\n",
      "1200/1200 - 1s - loss: 0.6751 - accuracy: 0.6958 - val_loss: 0.6685 - val_accuracy: 0.6991 - 1s/epoch - 938us/step\n",
      "Epoch 26/50\n",
      "1200/1200 - 1s - loss: 0.6748 - accuracy: 0.6954 - val_loss: 0.6691 - val_accuracy: 0.6999 - 1s/epoch - 924us/step\n",
      "Epoch 27/50\n",
      "1200/1200 - 1s - loss: 0.6734 - accuracy: 0.6978 - val_loss: 0.6657 - val_accuracy: 0.6982 - 1s/epoch - 934us/step\n",
      "Epoch 28/50\n",
      "1200/1200 - 1s - loss: 0.6740 - accuracy: 0.6950 - val_loss: 0.6657 - val_accuracy: 0.6976 - 1s/epoch - 945us/step\n",
      "Epoch 29/50\n",
      "1200/1200 - 1s - loss: 0.6727 - accuracy: 0.6971 - val_loss: 0.6690 - val_accuracy: 0.7002 - 1s/epoch - 938us/step\n",
      "Epoch 30/50\n",
      "1200/1200 - 1s - loss: 0.6720 - accuracy: 0.6971 - val_loss: 0.6673 - val_accuracy: 0.6983 - 1s/epoch - 953us/step\n",
      "Epoch 31/50\n",
      "1200/1200 - 1s - loss: 0.6716 - accuracy: 0.6975 - val_loss: 0.6681 - val_accuracy: 0.7003 - 1s/epoch - 937us/step\n",
      "Epoch 32/50\n",
      "1200/1200 - 1s - loss: 0.6706 - accuracy: 0.6971 - val_loss: 0.6720 - val_accuracy: 0.6955 - 1s/epoch - 932us/step\n",
      "Epoch 33/50\n",
      "1200/1200 - 1s - loss: 0.6707 - accuracy: 0.6962 - val_loss: 0.6655 - val_accuracy: 0.6967 - 1s/epoch - 923us/step\n",
      "Epoch 34/50\n",
      "1200/1200 - 1s - loss: 0.6704 - accuracy: 0.6960 - val_loss: 0.6694 - val_accuracy: 0.6973 - 1s/epoch - 957us/step\n",
      "Epoch 35/50\n",
      "1200/1200 - 1s - loss: 0.6694 - accuracy: 0.6970 - val_loss: 0.6633 - val_accuracy: 0.7004 - 1s/epoch - 930us/step\n",
      "Epoch 36/50\n",
      "1200/1200 - 1s - loss: 0.6685 - accuracy: 0.6982 - val_loss: 0.6640 - val_accuracy: 0.6986 - 1s/epoch - 938us/step\n",
      "Epoch 37/50\n",
      "1200/1200 - 1s - loss: 0.6689 - accuracy: 0.6989 - val_loss: 0.6620 - val_accuracy: 0.6983 - 1s/epoch - 943us/step\n",
      "Epoch 38/50\n",
      "1200/1200 - 1s - loss: 0.6672 - accuracy: 0.7000 - val_loss: 0.6640 - val_accuracy: 0.6996 - 1s/epoch - 946us/step\n",
      "Epoch 39/50\n",
      "1200/1200 - 1s - loss: 0.6679 - accuracy: 0.6970 - val_loss: 0.6713 - val_accuracy: 0.6966 - 1s/epoch - 922us/step\n",
      "Epoch 40/50\n",
      "1200/1200 - 1s - loss: 0.6674 - accuracy: 0.6982 - val_loss: 0.6642 - val_accuracy: 0.6990 - 1s/epoch - 925us/step\n",
      "Epoch 41/50\n",
      "1200/1200 - 1s - loss: 0.6670 - accuracy: 0.6984 - val_loss: 0.6628 - val_accuracy: 0.6984 - 1s/epoch - 957us/step\n",
      "Epoch 42/50\n",
      "1200/1200 - 1s - loss: 0.6665 - accuracy: 0.6976 - val_loss: 0.6619 - val_accuracy: 0.6995 - 1s/epoch - 942us/step\n",
      "Epoch 43/50\n",
      "1200/1200 - 1s - loss: 0.6655 - accuracy: 0.6992 - val_loss: 0.6621 - val_accuracy: 0.6990 - 1s/epoch - 942us/step\n",
      "Epoch 44/50\n",
      "1200/1200 - 1s - loss: 0.6653 - accuracy: 0.6992 - val_loss: 0.6657 - val_accuracy: 0.6990 - 1s/epoch - 935us/step\n",
      "Epoch 45/50\n",
      "1200/1200 - 1s - loss: 0.6658 - accuracy: 0.6985 - val_loss: 0.6647 - val_accuracy: 0.6963 - 1s/epoch - 930us/step\n",
      "Epoch 46/50\n",
      "1200/1200 - 1s - loss: 0.6655 - accuracy: 0.6989 - val_loss: 0.6617 - val_accuracy: 0.6992 - 1s/epoch - 977us/step\n",
      "Epoch 47/50\n",
      "1200/1200 - 1s - loss: 0.6643 - accuracy: 0.6999 - val_loss: 0.6655 - val_accuracy: 0.6980 - 1s/epoch - 966us/step\n",
      "Epoch 48/50\n",
      "1200/1200 - 1s - loss: 0.6644 - accuracy: 0.6990 - val_loss: 0.6614 - val_accuracy: 0.7026 - 1s/epoch - 961us/step\n",
      "Epoch 49/50\n",
      "1200/1200 - 1s - loss: 0.6640 - accuracy: 0.6989 - val_loss: 0.6684 - val_accuracy: 0.6990 - 1s/epoch - 949us/step\n",
      "Epoch 50/50\n",
      "1200/1200 - 1s - loss: 0.6636 - accuracy: 0.6993 - val_loss: 0.6617 - val_accuracy: 0.6990 - 1s/epoch - 961us/step\n",
      "Test Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_integers = label_encoder.fit_transform(y)\n",
    "y_encoded = to_categorical(y_integers, num_classes=3)\n",
    "\n",
    "# Step 2: Normalize the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape input data to be 3D [samples, time_steps, features] for RNN\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Step 4: Create RNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(3, activation='softmax')) # Output layer with 3 units for each class\n",
    "\n",
    "# Step 5: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
